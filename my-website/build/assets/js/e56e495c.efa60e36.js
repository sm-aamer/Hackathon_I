"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[3055],{1916(n,e,t){t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-4/chapter-2-cognitive-planning","title":"Cognitive Planning with LLMs","description":"Learn how to use Large Language Models for cognitive planning in robotics, decomposing complex natural language commands into sequences of ROS 2 actions.","source":"@site/docs/module-4/chapter-2-cognitive-planning.md","sourceDirName":"module-4","slug":"/module-4/chapter-2-cognitive-planning","permalink":"/docs/module-4/chapter-2-cognitive-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4/chapter-2-cognitive-planning.md","tags":[{"inline":true,"label":"llm","permalink":"/docs/tags/llm"},{"inline":true,"label":"cognitive-planning","permalink":"/docs/tags/cognitive-planning"},{"inline":true,"label":"gpt","permalink":"/docs/tags/gpt"},{"inline":true,"label":"natural-language","permalink":"/docs/tags/natural-language"},{"inline":true,"label":"ros2-actions","permalink":"/docs/tags/ros-2-actions"},{"inline":true,"label":"multi-step-planning","permalink":"/docs/tags/multi-step-planning"}],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Cognitive Planning with LLMs","sidebar_position":3,"tags":["llm","cognitive-planning","gpt","natural-language","ros2-actions","multi-step-planning"],"description":"Learn how to use Large Language Models for cognitive planning in robotics, decomposing complex natural language commands into sequences of ROS 2 actions."},"sidebar":"tutorialSidebar","previous":{"title":"Voice-to-Action Pipeline","permalink":"/docs/module-4/chapter-1-voice-to-action"},"next":{"title":"Autonomous Humanoid Capstone","permalink":"/docs/module-4/chapter-3-autonomous-humanoid"}}');var a=t(4848),o=t(8453);const s={title:"Cognitive Planning with LLMs",sidebar_position:3,tags:["llm","cognitive-planning","gpt","natural-language","ros2-actions","multi-step-planning"],description:"Learn how to use Large Language Models for cognitive planning in robotics, decomposing complex natural language commands into sequences of ROS 2 actions."},r="Cognitive Planning with LLMs",l={},c=[{value:"Overview of Cognitive Planning in Robotics",id:"overview-of-cognitive-planning-in-robotics",level:2},{value:"LLM Integration for Cognitive Planning",id:"llm-integration-for-cognitive-planning",level:2},{value:"Choosing the Right LLM for Robotics",id:"choosing-the-right-llm-for-robotics",level:3},{value:"Model Capabilities",id:"model-capabilities",level:4},{value:"Practical Considerations",id:"practical-considerations",level:4},{value:"Structured Prompting for Action Planning",id:"structured-prompting-for-action-planning",level:3},{value:"Natural Language Decomposition into Action Sequences",id:"natural-language-decomposition-into-action-sequences",level:2},{value:"Understanding Command Complexity",id:"understanding-command-complexity",level:3},{value:"Simple Commands",id:"simple-commands",level:4},{value:"Medium Complexity Commands",id:"medium-complexity-commands",level:4},{value:"Complex Commands",id:"complex-commands",level:4},{value:"Decomposition Strategies",id:"decomposition-strategies",level:3},{value:"Sequential Decomposition",id:"sequential-decomposition",level:4},{value:"Hierarchical Decomposition",id:"hierarchical-decomposition",level:4},{value:"ROS 2 Action Plan Generation",id:"ros-2-action-plan-generation",level:2},{value:"Converting LLM Output to Executable Actions",id:"converting-llm-output-to-executable-actions",level:3},{value:"Practical Examples of Cognitive Planning Implementations",id:"practical-examples-of-cognitive-planning-implementations",level:2},{value:"Example 1: Multi-Room Navigation and Object Retrieval",id:"example-1-multi-room-navigation-and-object-retrieval",level:3},{value:"Example 2: Conditional Task Execution",id:"example-2-conditional-task-execution",level:3},{value:"Configuration Examples for LLM Integration",id:"configuration-examples-for-llm-integration",level:2},{value:"LLM Configuration Parameters",id:"llm-configuration-parameters",level:3},{value:"System Prompt Configuration",id:"system-prompt-configuration",level:3},{value:"Code Snippets for LLM-Based Planning Systems",id:"code-snippets-for-llm-based-planning-systems",level:2},{value:"Error Handling and Recovery",id:"error-handling-and-recovery",level:3},{value:"Exercises for Cognitive Planning Implementations",id:"exercises-for-cognitive-planning-implementations",level:2},{value:"Exercise 1: Basic Multi-Step Planning",id:"exercise-1-basic-multi-step-planning",level:3},{value:"Exercise 2: Context-Aware Planning",id:"exercise-2-context-aware-planning",level:3},{value:"Exercise 3: Error Recovery Planning",id:"exercise-3-error-recovery-planning",level:3},{value:"Summary",id:"summary",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"cognitive-planning-with-llms",children:"Cognitive Planning with LLMs"})}),"\n",(0,a.jsx)(e.p,{children:"This chapter explores the use of Large Language Models (LLMs) for cognitive planning in robotics. We'll learn how to decompose complex natural language commands into sequences of ROS 2 actions, enabling robots to understand and execute sophisticated multi-step tasks. This represents the advanced cognitive capabilities that differentiate Vision-Language-Action (VLA) systems from simple command-response systems."}),"\n",(0,a.jsx)(e.h2,{id:"overview-of-cognitive-planning-in-robotics",children:"Overview of Cognitive Planning in Robotics"}),"\n",(0,a.jsx)(e.p,{children:"Cognitive planning with LLMs enables robots to:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Understand complex, multi-step natural language commands"}),"\n",(0,a.jsx)(e.li,{children:"Decompose high-level goals into actionable steps"}),"\n",(0,a.jsx)(e.li,{children:"Reason about the environment and available resources"}),"\n",(0,a.jsx)(e.li,{children:"Generate executable action plans that achieve the desired outcome"}),"\n",(0,a.jsx)(e.li,{children:"Handle ambiguity and provide feedback when clarification is needed"}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"Unlike simple command mapping, cognitive planning involves higher-level reasoning that allows robots to adapt to different situations and contexts."}),"\n",(0,a.jsx)(e.h2,{id:"llm-integration-for-cognitive-planning",children:"LLM Integration for Cognitive Planning"}),"\n",(0,a.jsx)(e.h3,{id:"choosing-the-right-llm-for-robotics",children:"Choosing the Right LLM for Robotics"}),"\n",(0,a.jsx)(e.p,{children:"When selecting an LLM for cognitive planning in robotics, consider these factors:"}),"\n",(0,a.jsx)(e.h4,{id:"model-capabilities",children:"Model Capabilities"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Reasoning ability"}),": The model's capacity to understand and decompose complex tasks"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Instruction following"}),": How well the model follows specific instructions and formatting"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Knowledge cutoff"}),": The date of the model's training data and its relevance to current robotics knowledge"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Context window"}),": The amount of information the model can process at once"]}),"\n"]}),"\n",(0,a.jsx)(e.h4,{id:"practical-considerations",children:"Practical Considerations"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Latency"}),": Response time is crucial for interactive applications"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Cost"}),": API costs can add up quickly in production systems"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Reliability"}),": Availability and consistency of the service"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Safety"}),": The model's tendency to generate harmful or incorrect outputs"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"structured-prompting-for-action-planning",children:"Structured Prompting for Action Planning"}),"\n",(0,a.jsx)(e.p,{children:"Effective cognitive planning requires carefully crafted prompts that guide the LLM to generate structured outputs suitable for robot action execution:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import openai\nimport json\nfrom typing import Dict, List, Any, Optional\n\nclass LLMBehaviorPlanner:\n    def __init__(self, api_key: str, model: str = "gpt-4"):\n        openai.api_key = api_key\n        self.model = model\n\n    async def plan_behavior(self,\n                          command: str,\n                          robot_capabilities: Dict[str, Any],\n                          environment_state: Dict[str, Any],\n                          context_history: List[Dict[str, str]] = None) -> Dict[str, Any]:\n        """\n        Generate a sequence of actions from a natural language command using LLM\n        """\n        # Build context for the LLM\n        context_prompt = self._build_context_prompt(\n            command,\n            robot_capabilities,\n            environment_state,\n            context_history\n        )\n\n        # Define the expected output format\n        format_instruction = """\n        Respond in the following JSON format:\n        {\n            "plan_id": "unique identifier for this plan",\n            "command_understanding": "brief summary of what the user wants",\n            "action_sequence": [\n                {\n                    "step": 1,\n                    "action_type": "NAVIGATION | MANIPULATION | PERCEPTION | QUERY | WAIT",\n                    "description": "what this step does",\n                    "parameters": {\n                        // specific parameters for the action type\n                    },\n                    "estimated_duration": "estimated time in seconds",\n                    "confidence": "0.0-1.0 confidence in this step"\n                }\n            ],\n            "potential_issues": ["list of potential problems"],\n            "success_criteria": "how to verify the command was executed successfully"\n        }\n        """\n\n        try:\n            response = await openai.ChatCompletion.acreate(\n                model=self.model,\n                messages=[\n                    {"role": "system", "content": self._get_system_prompt()},\n                    {"role": "user", "content": f"{context_prompt}\\n\\n{format_instruction}"}\n                ],\n                temperature=0.2,  # Low temperature for more consistent planning\n                max_tokens=1000\n            )\n\n            # Parse the response\n            result = json.loads(response.choices[0].message.content)\n\n            # Validate the plan\n            if not self._validate_action_sequence(result.get("action_sequence", [])):\n                raise ValueError("Generated action sequence is invalid")\n\n            return result\n\n        except json.JSONDecodeError:\n            return {\n                "plan_id": "error",\n                "command_understanding": "Could not parse LLM response",\n                "action_sequence": [],\n                "potential_issues": ["LLM response format was invalid"],\n                "success_criteria": "No plan generated"\n            }\n        except Exception as e:\n            return {\n                "plan_id": "error",\n                "command_understanding": f"Error generating plan: {str(e)}",\n                "action_sequence": [],\n                "potential_issues": [str(e)],\n                "success_criteria": "No plan generated"\n            }\n\n    def _build_context_prompt(self,\n                             command: str,\n                             robot_capabilities: Dict[str, Any],\n                             environment_state: Dict[str, Any],\n                             context_history: List[Dict[str, str]] = None) -> str:\n        """\n        Build a comprehensive context prompt for the LLM\n        """\n        context_parts = []\n\n        # Robot capabilities\n        capabilities_desc = []\n        if robot_capabilities.get("mobility", False):\n            capabilities_desc.append("The robot can move around the environment")\n        if robot_capabilities.get("manipulation", False):\n            capabilities_desc.append("The robot can manipulate objects")\n        if robot_capabilities.get("perception", False):\n            capabilities_desc.append("The robot can perceive its environment")\n\n        context_parts.append(f"Robot Capabilities: {\', \'.join(capabilities_desc)}")\n\n        # Environment state\n        if environment_state:\n            context_parts.append(f"Environment State: {json.dumps(environment_state, indent=2)}")\n\n        # Context history (for multi-turn interactions)\n        if context_history:\n            history_str = "\\n".join([f"- {entry.get(\'role\', \'user\')}: {entry.get(\'content\', \'\')}"\n                                   for entry in context_history[-3:]])  # Last 3 exchanges\n            context_parts.append(f"Recent Interaction History:\\n{history_str}")\n\n        # The actual command\n        context_parts.append(f"User Command: \'{command}\'")\n\n        return "\\n\\n".join(context_parts)\n\n    def _get_system_prompt(self) -> str:\n        """\n        System prompt to guide the LLM\'s behavior planning\n        """\n        return """\n        You are an expert robot behavior planner. Your job is to decompose natural language commands\n        into executable action sequences for a robot. Consider:\n\n        1. The robot\'s capabilities and limitations\n        2. The current environment and its constraints\n        3. The most efficient sequence of actions to achieve the goal\n        4. Potential obstacles and how to handle them\n        5. Safety considerations\n\n        Always respond in the specified JSON format. Be precise and realistic about what the robot can do.\n        """\n\n    def _validate_action_sequence(self, action_sequence: List[Dict[str, Any]]) -> bool:\n        """\n        Validate that the action sequence is reasonable\n        """\n        if not action_sequence:\n            return False\n\n        for step in action_sequence:\n            if not isinstance(step, dict):\n                return False\n            if "action_type" not in step or "parameters" not in step:\n                return False\n            if step["action_type"] not in ["NAVIGATION", "MANIPULATION", "PERCEPTION", "QUERY", "WAIT"]:\n                return False\n\n        return True\n'})}),"\n",(0,a.jsx)(e.h2,{id:"natural-language-decomposition-into-action-sequences",children:"Natural Language Decomposition into Action Sequences"}),"\n",(0,a.jsx)(e.h3,{id:"understanding-command-complexity",children:"Understanding Command Complexity"}),"\n",(0,a.jsx)(e.p,{children:"Natural language commands can vary greatly in complexity. The LLM-based cognitive planner must handle:"}),"\n",(0,a.jsx)(e.h4,{id:"simple-commands",children:"Simple Commands"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:'"Move forward 1 meter"'}),"\n",(0,a.jsx)(e.li,{children:'"Turn left"'}),"\n",(0,a.jsx)(e.li,{children:'"Pick up the red block"'}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"These require minimal decomposition and can often map directly to single robot actions."}),"\n",(0,a.jsx)(e.h4,{id:"medium-complexity-commands",children:"Medium Complexity Commands"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:'"Go to the kitchen and bring me a cup"'}),"\n",(0,a.jsx)(e.li,{children:'"Find the blue pen and put it in the drawer"'}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"These require a sequence of 2-4 actions involving navigation, perception, and manipulation."}),"\n",(0,a.jsx)(e.h4,{id:"complex-commands",children:"Complex Commands"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:'"Clean up the workspace by putting all the papers in the recycling bin and all the pens in the desk organizer"'}),"\n",(0,a.jsx)(e.li,{children:'"Go to the meeting room, check if John is there, and if he is, tell him to join the conference call in 5 minutes"'}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"These require sophisticated planning involving conditional logic, multiple subtasks, and context awareness."}),"\n",(0,a.jsx)(e.h3,{id:"decomposition-strategies",children:"Decomposition Strategies"}),"\n",(0,a.jsx)(e.h4,{id:"sequential-decomposition",children:"Sequential Decomposition"}),"\n",(0,a.jsx)(e.p,{children:"Break down commands into a linear sequence of steps:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'class SequentialDecomposer:\n    """\n    Decomposes commands into a linear sequence of actions\n    """\n    def __init__(self, llm_planner: LLMBehaviorPlanner):\n        self.planner = llm_planner\n\n    async def decompose(self, command: str, context: Dict[str, Any]) -> List[Dict[str, Any]]:\n        # For simple sequential tasks, we can use direct LLM planning\n        plan = await self.planner.plan_behavior(command, context["capabilities"], context["environment"])\n        return plan["action_sequence"]\n'})}),"\n",(0,a.jsx)(e.h4,{id:"hierarchical-decomposition",children:"Hierarchical Decomposition"}),"\n",(0,a.jsx)(e.p,{children:"Break down complex commands into subgoals and then decompose each subgoal:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'class HierarchicalDecomposer:\n    """\n    Decomposes commands hierarchically into subgoals\n    """\n    def __init__(self, llm_planner: LLMBehaviorPlanner):\n        self.planner = llm_planner\n\n    async def decompose(self, command: str, context: Dict[str, Any]) -> List[Dict[str, Any]]:\n        # First, ask the LLM to identify subgoals\n        subgoal_prompt = f"""\n        Decompose the following command into high-level subgoals:\n        Command: "{command}"\n\n        Respond in JSON format:\n        {{\n            "subgoals": [\n                {{"id": 1, "description": "first subgoal"}},\n                {{"id": 2, "description": "second subgoal"}}\n            ]\n        }}\n        """\n\n        try:\n            response = await openai.ChatCompletion.acreate(\n                model=self.planner.model,\n                messages=[\n                    {"role": "system", "content": "You are a task decomposition expert."},\n                    {"role": "user", "content": subgoal_prompt}\n                ],\n                temperature=0.1\n            )\n\n            subgoals = json.loads(response.choices[0].message.content)["subgoals"]\n\n            # Decompose each subgoal individually\n            all_actions = []\n            for subgoal in subgoals:\n                subgoal_plan = await self.planner.plan_behavior(\n                    subgoal["description"],\n                    context["capabilities"],\n                    context["environment"]\n                )\n                all_actions.extend(subgoal_plan["action_sequence"])\n\n            return all_actions\n\n        except Exception as e:\n            # Fallback to direct decomposition\n            return await self.direct_decompose(command, context)\n\n    async def direct_decompose(self, command: str, context: Dict[str, Any]) -> List[Dict[str, Any]]:\n        """\n        Fallback to direct decomposition if hierarchical fails\n        """\n        plan = await self.planner.plan_behavior(command, context["capabilities"], context["environment"])\n        return plan["action_sequence"]\n'})}),"\n",(0,a.jsx)(e.h2,{id:"ros-2-action-plan-generation",children:"ROS 2 Action Plan Generation"}),"\n",(0,a.jsx)(e.h3,{id:"converting-llm-output-to-executable-actions",children:"Converting LLM Output to Executable Actions"}),"\n",(0,a.jsx)(e.p,{children:"The cognitive planner must convert the LLM's structured output into actual ROS 2 action calls:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.action import ActionClient\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import PoseStamped, Point\nfrom std_msgs.msg import String\nfrom typing import Dict, Any, List\n\nclass ROS2ActionGenerator(Node):\n    def __init__(self):\n        super().__init__('llm_action_generator')\n\n        # Action clients for different types of actions\n        self.nav_client = ActionClient(self, NavigateToPose, 'navigate_to_pose')\n        self.manipulation_client = ActionClient(self, ManipulateObject, 'manipulate_object')\n        self.perception_client = ActionClient(self, PerceiveScene, 'perceive_scene')\n\n        # Publishers for status updates\n        self.status_pub = self.create_publisher(String, 'behavior_status', 10)\n\n        self.get_logger().info(\"LLM Action Generator initialized\")\n\n    async def execute_action_sequence(self, action_sequence: List[Dict[str, Any]],\n                                   success_callback=None, failure_callback=None):\n        \"\"\"\n        Execute a sequence of actions generated by the LLM\n        \"\"\"\n        for i, action in enumerate(action_sequence):\n            self.get_logger().info(f\"Executing action {i+1}/{len(action_sequence)}: {action['action_type']}\")\n\n            success = await self.execute_single_action(action)\n\n            if not success:\n                self.get_logger().error(f\"Action {i+1} failed: {action}\")\n                if failure_callback:\n                    await failure_callback(action_sequence, i, action)\n                return False\n\n            # Publish status update\n            status_msg = String()\n            status_msg.data = f\"Completed action {i+1}/{len(action_sequence)}: {action['description']}\"\n            self.status_pub.publish(status_msg)\n\n        self.get_logger().info(\"Action sequence completed successfully\")\n        if success_callback:\n            await success_callback(action_sequence)\n\n        return True\n\n    async def execute_single_action(self, action: Dict[str, Any]) -> bool:\n        \"\"\"\n        Execute a single action based on its type\n        \"\"\"\n        action_type = action.get('action_type', '').upper()\n\n        if action_type == 'NAVIGATION':\n            return await self.execute_navigation_action(action['parameters'])\n        elif action_type == 'MANIPULATION':\n            return await self.execute_manipulation_action(action['parameters'])\n        elif action_type == 'PERCEPTION':\n            return await self.execute_perception_action(action['parameters'])\n        elif action_type == 'QUERY':\n            return await self.execute_query_action(action['parameters'])\n        elif action_type == 'WAIT':\n            return await self.execute_wait_action(action['parameters'])\n        else:\n            self.get_logger().error(f\"Unknown action type: {action_type}\")\n            return False\n\n    async def execute_navigation_action(self, params: Dict[str, Any]) -> bool:\n        \"\"\"\n        Execute navigation action\n        \"\"\"\n        if not self.nav_client.wait_for_server(timeout_sec=5.0):\n            self.get_logger().error(\"Navigation action server not available\")\n            return False\n\n        goal_msg = NavigateToPose.Goal()\n\n        # Parse navigation parameters\n        if 'position' in params:\n            pos = params['position']\n            goal_msg.pose.pose.position.x = pos.get('x', 0.0)\n            goal_msg.pose.pose.position.y = pos.get('y', 0.0)\n            goal_msg.pose.pose.position.z = pos.get('z', 0.0)\n\n        if 'orientation' in params:\n            orient = params['orientation']\n            goal_msg.pose.pose.orientation.x = orient.get('x', 0.0)\n            goal_msg.pose.pose.orientation.y = orient.get('y', 0.0)\n            goal_msg.pose.pose.orientation.z = orient.get('z', 0.0)\n            goal_msg.pose.pose.orientation.w = orient.get('w', 1.0)\n\n        if 'frame_id' in params:\n            goal_msg.pose.header.frame_id = params['frame_id']\n        else:\n            goal_msg.pose.header.frame_id = 'map'\n\n        goal_msg.pose.header.stamp = self.get_clock().now().to_msg()\n\n        # Send goal and wait for result\n        goal_handle = await self.nav_client.send_goal_async(goal_msg)\n\n        if not goal_handle.accepted:\n            self.get_logger().error(\"Navigation goal was rejected\")\n            return False\n\n        result = await goal_handle.get_result_async()\n\n        return result.result.success  # Assuming the result has a success field\n\n    async def execute_manipulation_action(self, params: Dict[str, Any]) -> bool:\n        \"\"\"\n        Execute manipulation action\n        \"\"\"\n        if not self.manipulation_client.wait_for_server(timeout_sec=5.0):\n            self.get_logger().error(\"Manipulation action server not available\")\n            return False\n\n        goal_msg = ManipulateObject.Goal()\n\n        # Parse manipulation parameters\n        if 'object_id' in params:\n            goal_msg.object_id = params['object_id']\n\n        if 'action' in params:\n            # Map natural language action to enum\n            action_map = {\n                'pick': ManipulateObject.PICK_UP,\n                'place': ManipulateObject.PLACE_DOWN,\n                'grasp': ManipulateObject.GRASP,\n                'release': ManipulateObject.RELEASE\n            }\n            action_str = params['action'].lower()\n            goal_msg.action = action_map.get(action_str, ManipulateObject.UNKNOWN)\n\n        if 'target_position' in params:\n            goal_msg.target_pose.position = Point(**params['target_position'])\n\n        # Send goal and wait for result\n        goal_handle = await self.manipulation_client.send_goal_async(goal_msg)\n\n        if not goal_handle.accepted:\n            self.get_logger().error(\"Manipulation goal was rejected\")\n            return False\n\n        result = await goal_handle.get_result_async()\n\n        return result.result.success\n\n    async def execute_perception_action(self, params: Dict[str, Any]) -> bool:\n        \"\"\"\n        Execute perception action\n        \"\"\"\n        if not self.perception_client.wait_for_server(timeout_sec=5.0):\n            self.get_logger().error(\"Perception action server not available\")\n            return False\n\n        goal_msg = PerceiveScene.Goal()\n\n        # Parse perception parameters\n        if 'target_object' in params:\n            goal_msg.target_object = params['target_object']\n\n        if 'search_area' in params:\n            # Assuming search_area has min/max coordinates\n            goal_msg.search_area.min_corner.x = params['search_area'].get('min_x', -10.0)\n            goal_msg.search_area.min_corner.y = params['search_area'].get('min_y', -10.0)\n            goal_msg.search_area.max_corner.x = params['search_area'].get('max_x', 10.0)\n            goal_msg.search_area.max_corner.y = params['search_area'].get('max_y', 10.0)\n\n        # Send goal and wait for result\n        goal_handle = await self.perception_client.send_goal_async(goal_msg)\n\n        if not goal_handle.accepted:\n            self.get_logger().error(\"Perception goal was rejected\")\n            return False\n\n        result = await goal_handle.get_result_async()\n\n        # Update environment state with perceived information\n        if result.result.objects_found:\n            self.get_logger().info(f\"Found {len(result.result.objects_found)} objects\")\n\n        return result.result.success\n\n    async def execute_query_action(self, params: Dict[str, Any]) -> bool:\n        \"\"\"\n        Execute query action (information gathering)\n        \"\"\"\n        # For now, this just logs the query\n        query_text = params.get('query', 'unknown')\n        self.get_logger().info(f\"Query action: {query_text}\")\n\n        # In a real system, this might involve:\n        # - Querying a knowledge base\n        # - Asking the user for clarification\n        # - Checking robot's internal state\n        # - Looking up information in the environment\n\n        return True\n\n    async def execute_wait_action(self, params: Dict[str, Any]) -> bool:\n        \"\"\"\n        Execute wait action\n        \"\"\"\n        duration = params.get('duration', 1.0)  # Default to 1 second\n        self.get_logger().info(f\"Waiting for {duration} seconds\")\n\n        # In a real ROS 2 system, we'd use a timer or similar mechanism\n        # For this example, we'll just return True immediately\n        # In practice, you'd want to properly wait while keeping the node responsive\n\n        return True\n"})}),"\n",(0,a.jsx)(e.h2,{id:"practical-examples-of-cognitive-planning-implementations",children:"Practical Examples of Cognitive Planning Implementations"}),"\n",(0,a.jsx)(e.h3,{id:"example-1-multi-room-navigation-and-object-retrieval",children:"Example 1: Multi-Room Navigation and Object Retrieval"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'class MultiStepTaskPlanner:\n    """\n    Example implementation of a complex multi-step task\n    """\n    def __init__(self, llm_planner: LLMBehaviorPlanner, action_generator: ROS2ActionGenerator):\n        self.llm_planner = llm_planner\n        self.action_generator = action_generator\n\n    async def execute_fetch_task(self, item_description: str, destination: str) -> bool:\n        """\n        Execute a task like "Go to the kitchen, find a red cup, and bring it to the living room"\n        """\n        command = f"Go to the {destination}, find a {item_description}, and bring it to me"\n\n        # Define robot capabilities\n        capabilities = {\n            "mobility": True,\n            "manipulation": True,\n            "perception": True\n        }\n\n        # Get current environment state (in a real system, this would come from sensors)\n        environment_state = {\n            "known_rooms": ["kitchen", "living room", "bedroom", "office"],\n            "robot_location": "starting_position",\n            "known_objects": {\n                "kitchen": ["red cup", "blue mug", "plate"],\n                "living room": ["sofa", "coffee table", "TV"]\n            }\n        }\n\n        # Generate plan using LLM\n        plan = await self.llm_planner.plan_behavior(\n            command,\n            capabilities,\n            environment_state\n        )\n\n        if not plan["action_sequence"]:\n            self.action_generator.get_logger().error("No valid action sequence generated")\n            return False\n\n        # Execute the plan\n        success = await self.action_generator.execute_action_sequence(plan["action_sequence"])\n\n        return success\n'})}),"\n",(0,a.jsx)(e.h3,{id:"example-2-conditional-task-execution",children:"Example 2: Conditional Task Execution"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'class ConditionalTaskPlanner:\n    """\n    Example of handling conditional logic in cognitive planning\n    """\n    def __init__(self, llm_planner: LLMBehaviorPlanner, action_generator: ROS2ActionGenerator):\n        self.llm_planner = llm_planner\n        self.action_generator = action_generator\n        self.context_store = {}  # Store context between actions\n\n    async def execute_conditional_task(self, command: str) -> bool:\n        """\n        Execute a task that requires conditional logic\n        Example: "If John is in the office, tell him to attend the meeting. Otherwise, send him a message."\n        """\n        # First, break down the command into conditional parts\n        conditional_prompt = f"""\n        Analyze the following conditional command and break it into:\n        1. The condition to check\n        2. The action to take if condition is true\n        3. The action to take if condition is false\n\n        Command: "{command}"\n\n        Respond in JSON format:\n        {{\n            "condition_check": "what to check",\n            "if_true_action": "action if condition is met",\n            "if_false_action": "action if condition is not met"\n        }}\n        """\n\n        try:\n            response = await openai.ChatCompletion.acreate(\n                model=self.llm_planner.model,\n                messages=[\n                    {"role": "system", "content": "You are a conditional statement analyzer for robotics tasks."},\n                    {"role": "user", "content": conditional_prompt}\n                ],\n                temperature=0.1\n            )\n\n            conditional_plan = json.loads(response.choices[0].message.content)\n\n            # First, execute the condition check\n            condition_result = await self.check_condition(conditional_plan["condition_check"])\n\n            # Execute appropriate action based on condition\n            if condition_result:\n                action_to_execute = conditional_plan["if_true_action"]\n            else:\n                action_to_execute = conditional_plan["if_false_action"]\n\n            # Generate and execute the specific action\n            specific_plan = await self.llm_planner.plan_behavior(\n                action_to_execute,\n                {"mobility": True, "communication": True},  # Capabilities needed\n                self.context_store.get("environment", {})\n            )\n\n            return await self.action_generator.execute_action_sequence(specific_plan["action_sequence"])\n\n        except Exception as e:\n            self.action_generator.get_logger().error(f"Error in conditional task: {str(e)}")\n            return False\n\n    async def check_condition(self, condition: str) -> bool:\n        """\n        Check if a condition is true (in a real system, this would involve perception)\n        """\n        # In a real system, this would involve:\n        # - Using perception to check the environment\n        # - Querying a knowledge base\n        # - Checking robot sensors\n\n        # For this example, we\'ll simulate a check\n        self.action_generator.get_logger().info(f"Checking condition: {condition}")\n\n        # Simulate a random result for demo purposes\n        import random\n        return random.choice([True, False])\n'})}),"\n",(0,a.jsx)(e.h2,{id:"configuration-examples-for-llm-integration",children:"Configuration Examples for LLM Integration"}),"\n",(0,a.jsx)(e.h3,{id:"llm-configuration-parameters",children:"LLM Configuration Parameters"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"# llm_config.py\nclass LLMConfig:\n    # API Configuration\n    API_KEY = os.getenv('OPENAI_API_KEY')\n    MODEL = os.getenv('LLM_MODEL', 'gpt-4')\n\n    # Planning Parameters\n    TEMPERATURE = float(os.getenv('LLM_TEMPERATURE', 0.2))  # Lower for more consistent planning\n    MAX_TOKENS = int(os.getenv('LLM_MAX_TOKENS', 1000))\n\n    # Confidence Thresholds\n    PLAN_CONFIDENCE_THRESHOLD = float(os.getenv('PLAN_CONFIDENCE_THRESHOLD', 0.7))\n    ACTION_CONFIDENCE_THRESHOLD = float(os.getenv('ACTION_CONFIDENCE_THRESHOLD', 0.6))\n\n    # Retry Configuration\n    MAX_PLANNING_RETRIES = int(os.getenv('MAX_PLANNING_RETRIES', 3))\n    PLANNING_RETRY_DELAY = float(os.getenv('PLANNING_RETRY_DELAY', 1.0))\n\n    # Context Management\n    MAX_CONTEXT_HISTORY = int(os.getenv('MAX_CONTEXT_HISTORY', 10))\n    CONTEXT_SUMMARIZATION_THRESHOLD = int(os.getenv('CONTEXT_SUMMARIZATION_THRESHOLD', 20))\n"})}),"\n",(0,a.jsx)(e.h3,{id:"system-prompt-configuration",children:"System Prompt Configuration"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# system_prompts.py\nSYSTEM_PROMPTS = {\n    "behavior_planner": """\n    You are an expert robot behavior planner. Your job is to decompose natural language commands\n    into executable action sequences for a robot. Consider:\n\n    1. The robot\'s capabilities and limitations\n    2. The current environment and its constraints\n    3. The most efficient sequence of actions to achieve the goal\n    4. Potential obstacles and how to handle them\n    5. Safety considerations\n\n    Always respond in the specified JSON format. Be precise and realistic about what the robot can do.\n    """,\n\n    "action_validator": """\n    You are an action sequence validator. Your job is to review action sequences generated by\n    a behavior planner and identify potential issues. Look for:\n\n    1. Logical sequence of actions\n    2. Physical feasibility given robot capabilities\n    3. Safety concerns\n    4. Missing preconditions\n    5. Contradictory actions\n\n    Rate each sequence as HIGH, MEDIUM, or LOW risk and provide specific feedback.\n    """,\n\n    "context_summarizer": """\n    You are a conversation and task context summarizer. Your job is to condense the history\n    of interactions and task executions into a brief summary that preserves important context\n    for future planning. Focus on:\n\n    1. Current robot state and location\n    2. Recently completed tasks\n    3. Known environment information\n    4. User preferences or instructions\n\n    Keep the summary concise but informative.\n    """\n}\n'})}),"\n",(0,a.jsx)(e.h2,{id:"code-snippets-for-llm-based-planning-systems",children:"Code Snippets for LLM-Based Planning Systems"}),"\n",(0,a.jsx)(e.h3,{id:"error-handling-and-recovery",children:"Error Handling and Recovery"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'class ResilientPlanner:\n    """\n    A planner with built-in error handling and recovery mechanisms\n    """\n    def __init__(self, llm_planner: LLMBehaviorPlanner, action_generator: ROS2ActionGenerator):\n        self.llm_planner = llm_planner\n        self.action_generator = action_generator\n        self.failure_history = []\n\n    async def execute_with_recovery(self, command: str, context: Dict[str, Any]) -> bool:\n        """\n        Execute a command with automatic recovery from failures\n        """\n        # Generate initial plan\n        plan = await self.llm_planner.plan_behavior(command,\n                                                   context["capabilities"],\n                                                   context["environment"])\n\n        if not plan["action_sequence"]:\n            return False\n\n        # Execute with failure callback for recovery\n        success = await self.action_generator.execute_action_sequence(\n            plan["action_sequence"],\n            success_callback=self.on_success,\n            failure_callback=self.on_failure_and_recovery\n        )\n\n        return success\n\n    async def on_failure_and_recovery(self, action_sequence: List[Dict[str, Any]],\n                                   failed_step_idx: int, failed_action: Dict[str, Any]):\n        """\n        Handle failure and attempt recovery\n        """\n        failed_action_copy = failed_action.copy()\n        self.failure_history.append({\n            "failed_action": failed_action_copy,\n            "step_index": failed_step_idx,\n            "timestamp": time.time()\n        })\n\n        # If we\'ve failed multiple times on the same action, try alternative\n        if self._is_recurring_failure(failed_action):\n            await self._try_alternative_approach(action_sequence, failed_step_idx, failed_action)\n        else:\n            # Try the same action again with modified parameters\n            await self._retry_with_modifications(action_sequence, failed_step_idx, failed_action)\n\n    def _is_recurring_failure(self, action: Dict[str, Any]) -> bool:\n        """\n        Check if this action has failed multiple times recently\n        """\n        recent_failures = [f for f in self.failure_history\n                          if f["failed_action"]["action_type"] == action["action_type"]\n                          and time.time() - f["timestamp"] < 300]  # Last 5 minutes\n\n        return len(recent_failures) >= 3\n\n    async def _try_alternative_approach(self, action_sequence: List[Dict[str, Any]],\n                                      failed_step_idx: int, failed_action: Dict[str, Any]):\n        """\n        Try an alternative approach when the same action keeps failing\n        """\n        # Ask the LLM for an alternative way to achieve the same goal\n        alternative_prompt = f"""\n        The following action keeps failing. Suggest an alternative approach to achieve the same goal:\n        Failed Action: {json.dumps(failed_action)}\n        Original Plan: {json.dumps(action_sequence)}\n\n        Respond with alternative actions that could achieve the same outcome.\n        """\n\n        try:\n            response = await openai.ChatCompletion.acreate(\n                model=self.llm_planner.model,\n                messages=[\n                    {"role": "system", "content": "You are a robotics expert who suggests alternative approaches when actions fail."},\n                    {"role": "user", "content": alternative_prompt}\n                ]\n            )\n\n            # Parse and execute the alternative approach\n            # (Implementation would continue from here)\n\n        except Exception as e:\n            self.action_generator.get_logger().error(f"Error in alternative approach: {str(e)}")\n\n    async def _retry_with_modifications(self, action_sequence: List[Dict[str, Any]],\n                                     failed_step_idx: int, failed_action: Dict[str, Any]):\n        """\n        Retry the failed action with modifications\n        """\n        # Modify parameters slightly and try again\n        modified_action = failed_action.copy()\n        if "precision" in modified_action["parameters"]:\n            # If it failed due to precision, try with lower precision\n            modified_action["parameters"]["precision"] *= 1.5\n\n        # Attempt to re-execute the modified action\n        success = await self.action_generator.execute_single_action(modified_action)\n\n        if not success:\n            self.action_generator.get_logger().error("Retry also failed")\n'})}),"\n",(0,a.jsx)(e.h2,{id:"exercises-for-cognitive-planning-implementations",children:"Exercises for Cognitive Planning Implementations"}),"\n",(0,a.jsx)(e.h3,{id:"exercise-1-basic-multi-step-planning",children:"Exercise 1: Basic Multi-Step Planning"}),"\n",(0,a.jsx)(e.p,{children:"Implement a system that can handle simple multi-step commands."}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Requirements"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Set up LLM integration for cognitive planning"}),"\n",(0,a.jsx)(e.li,{children:"Create a planner that can decompose simple multi-step commands"}),"\n",(0,a.jsx)(e.li,{children:"Execute the resulting action sequences using ROS 2"}),"\n",(0,a.jsx)(e.li,{children:"Validate that complex commands are properly decomposed"}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Steps"}),":"]}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsx)(e.li,{children:"Implement the LLMBehaviorPlanner class"}),"\n",(0,a.jsx)(e.li,{children:"Create action sequence validation"}),"\n",(0,a.jsx)(e.li,{children:"Connect to ROS 2 action servers"}),"\n",(0,a.jsx)(e.li,{children:'Test with multi-step commands like "Go to kitchen and find a cup"'}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"exercise-2-context-aware-planning",children:"Exercise 2: Context-Aware Planning"}),"\n",(0,a.jsx)(e.p,{children:"Extend the system to maintain and use context between commands."}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Requirements"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Maintain environment state between commands"}),"\n",(0,a.jsx)(e.li,{children:"Use context to inform planning decisions"}),"\n",(0,a.jsx)(e.li,{children:"Handle commands that reference previous actions or states"}),"\n",(0,a.jsx)(e.li,{children:"Implement context summarization for long-running interactions"}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Implementation"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Create a context manager for environment state"}),"\n",(0,a.jsx)(e.li,{children:"Modify the LLM planner to use context"}),"\n",(0,a.jsx)(e.li,{children:"Add context summarization for long histories"}),"\n",(0,a.jsx)(e.li,{children:"Test with context-dependent commands"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"exercise-3-error-recovery-planning",children:"Exercise 3: Error Recovery Planning"}),"\n",(0,a.jsx)(e.p,{children:"Implement sophisticated error handling and recovery mechanisms."}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Requirements"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Detect when actions fail during execution"}),"\n",(0,a.jsx)(e.li,{children:"Generate alternative approaches when failures occur"}),"\n",(0,a.jsx)(e.li,{children:"Learn from repeated failures to improve future planning"}),"\n",(0,a.jsx)(e.li,{children:"Provide graceful degradation when plans cannot be executed"}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Components"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Failure detection and logging"}),"\n",(0,a.jsx)(e.li,{children:"Alternative approach generation"}),"\n",(0,a.jsx)(e.li,{children:"Learning from failure patterns"}),"\n",(0,a.jsx)(e.li,{children:"Graceful degradation mechanisms"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(e.p,{children:"Cognitive planning with LLMs represents a significant advancement in robotics, enabling robots to understand and execute complex natural language commands through sophisticated reasoning and action decomposition. By combining the reasoning capabilities of LLMs with the precision of ROS 2 action execution, we create systems that can handle the ambiguity and complexity of natural language interaction. This chapter has covered the key components of cognitive planning: LLM integration, natural language decomposition, and ROS 2 action generation, providing the foundation for more advanced autonomous capabilities in the following chapter."})]})}function p(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}},8453(n,e,t){t.d(e,{R:()=>s,x:()=>r});var i=t(6540);const a={},o=i.createContext(a);function s(n){const e=i.useContext(o);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:s(n.components),i.createElement(o.Provider,{value:e},n.children)}}}]);