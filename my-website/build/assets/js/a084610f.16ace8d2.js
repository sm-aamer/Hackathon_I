"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[3541],{3330(n,e,i){i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-2/chapter-2-unity-interaction","title":"Chapter 2 - Unity for Human-Robot Interaction","description":"Introduction to Unity for Robotics","source":"@site/docs/module-2/chapter-2-unity-interaction.md","sourceDirName":"module-2","slug":"/module-2/chapter-2-unity-interaction","permalink":"/docs/module-2/chapter-2-unity-interaction","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2/chapter-2-unity-interaction.md","tags":[],"version":"current","frontMatter":{"id":"chapter-2-unity-interaction","sidebar_label":"Unity for Human-Robot Interaction","title":"Chapter 2 - Unity for Human-Robot Interaction"},"sidebar":"tutorialSidebar","previous":{"title":"Gazebo Simulation Basics","permalink":"/docs/module-2/chapter-1-gazebo-basics"},"next":{"title":"Sensor Simulation","permalink":"/docs/module-2/chapter-3-sensor-simulation"}}');var r=i(4848),o=i(8453);const s={id:"chapter-2-unity-interaction",sidebar_label:"Unity for Human-Robot Interaction",title:"Chapter 2 - Unity for Human-Robot Interaction"},a="Chapter 2: Unity for Human-Robot Interaction",l={},c=[{value:"Introduction to Unity for Robotics",id:"introduction-to-unity-for-robotics",level:2},{value:"Setting Up Unity for Robotics",id:"setting-up-unity-for-robotics",level:2},{value:"Unity Version Requirements",id:"unity-version-requirements",level:3},{value:"Unity Robotics Package",id:"unity-robotics-package",level:3},{value:"Installing Unity Robotics Package",id:"installing-unity-robotics-package",level:4},{value:"ROS Integration",id:"ros-integration",level:4},{value:"Environment Creation in Unity",id:"environment-creation-in-unity",level:2},{value:"Terrain and Ground Surfaces",id:"terrain-and-ground-surfaces",level:3},{value:"Creating Basic Terrain",id:"creating-basic-terrain",level:4},{value:"Terrain Settings for Robotics",id:"terrain-settings-for-robotics",level:4},{value:"Obstacles and Interactive Elements",id:"obstacles-and-interactive-elements",level:3},{value:"Creating Interactive Objects",id:"creating-interactive-objects",level:4},{value:"Physics Materials",id:"physics-materials",level:4},{value:"NavMesh for Robot Navigation",id:"navmesh-for-robot-navigation",level:3},{value:"Rendering Systems and Materials",id:"rendering-systems-and-materials",level:2},{value:"Universal Render Pipeline (URP)",id:"universal-render-pipeline-urp",level:3},{value:"Setting up URP",id:"setting-up-urp",level:4},{value:"Shader Selection for Robotics",id:"shader-selection-for-robotics",level:3},{value:"Metallic vs Standard Shaders",id:"metallic-vs-standard-shaders",level:4},{value:"Custom Shaders for Sensors",id:"custom-shaders-for-sensors",level:4},{value:"Lighting Systems",id:"lighting-systems",level:3},{value:"Light Types for Robotics",id:"light-types-for-robotics",level:4},{value:"Lighting Considerations for Perception",id:"lighting-considerations-for-perception",level:4},{value:"Human-Robot Interaction Elements",id:"human-robot-interaction-elements",level:2},{value:"User Interface Design",id:"user-interface-design",level:3},{value:"Canvas Setup for HRI",id:"canvas-setup-for-hri",level:4},{value:"Gesture Recognition",id:"gesture-recognition",level:3},{value:"Voice Command Simulation",id:"voice-command-simulation",level:3},{value:"Practical Examples",id:"practical-examples",level:2},{value:"Example 1: Creating a Basic Humanoid Robot Scene",id:"example-1-creating-a-basic-humanoid-robot-scene",level:3},{value:"Example 2: Unity Scene with Humanoid Robot Navigation",id:"example-2-unity-scene-with-humanoid-robot-navigation",level:3},{value:"Example 3: Sensor Visualization in Unity",id:"example-3-sensor-visualization-in-unity",level:3},{value:"Integration with Robotics Frameworks",id:"integration-with-robotics-frameworks",level:2},{value:"Unity-Rosbridge Integration",id:"unity-rosbridge-integration",level:3},{value:"Perception Pipeline",id:"perception-pipeline",level:3},{value:"Exercises for Students",id:"exercises-for-students",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"chapter-2-unity-for-human-robot-interaction",children:"Chapter 2: Unity for Human-Robot Interaction"})}),"\n",(0,r.jsx)(e.h2,{id:"introduction-to-unity-for-robotics",children:"Introduction to Unity for Robotics"}),"\n",(0,r.jsx)(e.p,{children:"Unity is a powerful game development engine that has found increasing applications in robotics simulation and human-robot interaction design. Its high-fidelity rendering capabilities and rich ecosystem of tools make it an excellent choice for creating immersive human-robot interaction scenarios."}),"\n",(0,r.jsx)(e.p,{children:"Unity offers several advantages for robotics:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"High-fidelity rendering with physically-based materials"}),"\n",(0,r.jsx)(e.li,{children:"Flexible lighting systems with real-time shadows"}),"\n",(0,r.jsx)(e.li,{children:"Powerful animation and physics systems"}),"\n",(0,r.jsx)(e.li,{children:"Extensive asset ecosystem through the Unity Asset Store"}),"\n",(0,r.jsx)(e.li,{children:"Cross-platform deployment capabilities"}),"\n",(0,r.jsx)(e.li,{children:"Strong community and documentation support"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"setting-up-unity-for-robotics",children:"Setting Up Unity for Robotics"}),"\n",(0,r.jsx)(e.p,{children:"Setting up Unity for robotics applications requires specific packages and configurations to handle robot models and their interactions effectively."}),"\n",(0,r.jsx)(e.h3,{id:"unity-version-requirements",children:"Unity Version Requirements"}),"\n",(0,r.jsx)(e.p,{children:"For robotics applications, Unity 2021.3 LTS or later is recommended for:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Long-term support and stability"}),"\n",(0,r.jsx)(e.li,{children:"Improved physics engine performance"}),"\n",(0,r.jsx)(e.li,{children:"Enhanced rendering capabilities"}),"\n",(0,r.jsx)(e.li,{children:"Better scripting performance"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"unity-robotics-package",children:"Unity Robotics Package"}),"\n",(0,r.jsx)(e.p,{children:"The Unity Robotics package provides essential tools for robotics simulation, including ROS integration and sensor simulation capabilities."}),"\n",(0,r.jsx)(e.h4,{id:"installing-unity-robotics-package",children:"Installing Unity Robotics Package"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Open Unity Hub and create a new project"}),"\n",(0,r.jsx)(e.li,{children:"In the Unity Editor, go to Window \u2192 Package Manager"}),"\n",(0,r.jsx)(e.li,{children:'Click the "+" icon and select "Add package from git URL..."'}),"\n",(0,r.jsxs)(e.li,{children:["Add the Unity Robotics packages:","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.code,{children:"com.unity.robotics.ros-tcp-connector"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.code,{children:"com.unity.robotics.urdf-importer"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.code,{children:"com.unity.robotics.robotics-from-unity"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"ros-integration",children:"ROS Integration"}),"\n",(0,r.jsx)(e.p,{children:"The ROS TCP Connector enables communication between Unity and ROS/ROS 2:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:'using Unity.Robotics.ROSTCPConnector;\n\npublic class RobotController : MonoBehaviour\n{\n    ROSConnection ros;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.RegisterPublisher<JointStateMsg>("joint_states");\n    }\n\n    void Update()\n    {\n        // Send joint states to ROS\n        JointStateMsg jointState = new JointStateMsg();\n        // Populate joint state message\n        ros.Publish("joint_states", jointState);\n    }\n}\n'})}),"\n",(0,r.jsx)(e.h2,{id:"environment-creation-in-unity",children:"Environment Creation in Unity"}),"\n",(0,r.jsx)(e.p,{children:"Creating realistic environments for humanoid robots in Unity involves several key components:"}),"\n",(0,r.jsx)(e.h3,{id:"terrain-and-ground-surfaces",children:"Terrain and Ground Surfaces"}),"\n",(0,r.jsx)(e.p,{children:"Creating realistic terrain that humanoid robots can navigate and interact with."}),"\n",(0,r.jsx)(e.h4,{id:"creating-basic-terrain",children:"Creating Basic Terrain"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"In Unity Editor, GameObject \u2192 3D Object \u2192 Terrain"}),"\n",(0,r.jsx)(e.li,{children:"Use the terrain tools to sculpt the landscape"}),"\n",(0,r.jsx)(e.li,{children:"Apply textures for different ground types"}),"\n",(0,r.jsx)(e.li,{children:"Add trees and vegetation using the terrain tools"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"terrain-settings-for-robotics",children:"Terrain Settings for Robotics"}),"\n",(0,r.jsx)(e.p,{children:"For robotics applications, consider:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Appropriate scale (1 Unity unit = 1 meter for realism)"}),"\n",(0,r.jsx)(e.li,{children:"Collision detection for navigation"}),"\n",(0,r.jsx)(e.li,{children:"Texture resolution suitable for perception tasks"}),"\n",(0,r.jsx)(e.li,{children:"LOD (Level of Detail) settings for performance"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"obstacles-and-interactive-elements",children:"Obstacles and Interactive Elements"}),"\n",(0,r.jsx)(e.p,{children:"Designing objects that robots can perceive and interact with in the environment."}),"\n",(0,r.jsx)(e.h4,{id:"creating-interactive-objects",children:"Creating Interactive Objects"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\n\npublic class InteractiveObject : MonoBehaviour\n{\n    public bool isGraspable = true;\n    public string objectType = "object";\n\n    void Start()\n    {\n        // Add colliders for physics interaction\n        if (!GetComponent<Collider>())\n            gameObject.AddComponent<BoxCollider>();\n\n        // Add rigidbody if object should be movable\n        if (isGraspable && !GetComponent<Rigidbody>())\n            gameObject.AddComponent<Rigidbody>();\n    }\n\n    void OnTriggerEnter(Collider other)\n    {\n        if (other.CompareTag("Robot"))\n        {\n            // Handle robot interaction\n            OnRobotInteraction(other.gameObject);\n        }\n    }\n\n    void OnRobotInteraction(GameObject robot)\n    {\n        // Implement interaction logic\n        Debug.Log($"Robot interacted with {gameObject.name}");\n    }\n}\n'})}),"\n",(0,r.jsx)(e.h4,{id:"physics-materials",children:"Physics Materials"}),"\n",(0,r.jsx)(e.p,{children:"For realistic physics interactions:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Create PhysicMaterial assets for different surface properties"}),"\n",(0,r.jsx)(e.li,{children:"Configure friction and bounce values appropriately"}),"\n",(0,r.jsx)(e.li,{children:"Apply materials to colliders for accurate simulation"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"navmesh-for-robot-navigation",children:"NavMesh for Robot Navigation"}),"\n",(0,r.jsx)(e.p,{children:"Setting up navigation meshes for pathfinding:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Select walkable surfaces"}),"\n",(0,r.jsx)(e.li,{children:"Go to Navigation window (Window \u2192 AI \u2192 Navigation)"}),"\n",(0,r.jsx)(e.li,{children:"Bake the NavMesh"}),"\n",(0,r.jsx)(e.li,{children:"Use NavMeshAgent for pathfinding in humanoid robots"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"rendering-systems-and-materials",children:"Rendering Systems and Materials"}),"\n",(0,r.jsx)(e.p,{children:"Unity's rendering pipeline offers advanced capabilities for creating photorealistic robot models and environments."}),"\n",(0,r.jsx)(e.h3,{id:"universal-render-pipeline-urp",children:"Universal Render Pipeline (URP)"}),"\n",(0,r.jsx)(e.p,{children:"For robotics applications, URP (Universal Render Pipeline) is often recommended:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Better performance for real-time simulation"}),"\n",(0,r.jsx)(e.li,{children:"Lower system requirements"}),"\n",(0,r.jsx)(e.li,{children:"Good visual quality for perception tasks"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"setting-up-urp",children:"Setting up URP"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Window \u2192 Package Manager \u2192 Universal RP"}),"\n",(0,r.jsx)(e.li,{children:"Create a new URP Asset: Assets \u2192 Create \u2192 Rendering \u2192 Universal Render Pipeline \u2192 Pipeline Asset"}),"\n",(0,r.jsx)(e.li,{children:"Assign the asset in Project Settings \u2192 Graphics \u2192 Scriptable Render Pipeline Settings"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"shader-selection-for-robotics",children:"Shader Selection for Robotics"}),"\n",(0,r.jsx)(e.p,{children:"Choosing appropriate shaders for different robot components and environmental elements."}),"\n",(0,r.jsx)(e.h4,{id:"metallic-vs-standard-shaders",children:"Metallic vs Standard Shaders"}),"\n",(0,r.jsx)(e.p,{children:"For metallic robot components:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Use Metallic workflow with appropriate metallic maps"}),"\n",(0,r.jsx)(e.li,{children:"Configure smoothness for different surface finishes"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"For organic/environmental elements:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Use Standard shader with specular workflow"}),"\n",(0,r.jsx)(e.li,{children:"Adjust albedo and normal maps for realistic appearance"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"custom-shaders-for-sensors",children:"Custom Shaders for Sensors"}),"\n",(0,r.jsx)(e.p,{children:"For sensor simulation, custom shaders can visualize:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"LiDAR point clouds"}),"\n",(0,r.jsx)(e.li,{children:"Depth camera data"}),"\n",(0,r.jsx)(e.li,{children:"Field of view visualization"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"Example sensor visualization shader:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-hlsl",children:'Shader "Robotics/SensorVisualization"\n{\n    Properties\n    {\n        _MainTex ("Texture", 2D) = "white" {}\n        _SensorColor ("Sensor Color", Color) = (1, 0, 0, 1)\n    }\n    SubShader\n    {\n        Tags { "RenderType"="Opaque" }\n        LOD 100\n\n        Pass\n        {\n            CGPROGRAM\n            #pragma vertex vert\n            #pragma fragment frag\n            #include "UnityCG.cginc"\n\n            struct appdata\n            {\n                float4 vertex : POSITION;\n                float2 uv : TEXCOORD0;\n            };\n\n            struct v2f\n            {\n                float2 uv : TEXCOORD0;\n                float4 vertex : SV_POSITION;\n            };\n\n            sampler2D _MainTex;\n            float4 _MainTex_ST;\n            float4 _SensorColor;\n\n            v2f vert (appdata v)\n            {\n                v2f o;\n                o.vertex = UnityObjectToClipPos(v.vertex);\n                o.uv = TRANSFORM_TEX(v.uv, _MainTex);\n                return o;\n            }\n\n            fixed4 frag (v2f i) : SV_Target\n            {\n                fixed4 col = tex2D(_MainTex, i.uv);\n                return lerp(col, _SensorColor, 0.3);\n            }\n            ENDCG\n        }\n    }\n}\n'})}),"\n",(0,r.jsx)(e.h3,{id:"lighting-systems",children:"Lighting Systems"}),"\n",(0,r.jsx)(e.p,{children:"Setting up realistic lighting that affects how robots perceive their environment."}),"\n",(0,r.jsx)(e.h4,{id:"light-types-for-robotics",children:"Light Types for Robotics"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Directional lights: Simulate sun or overhead lighting"}),"\n",(0,r.jsx)(e.li,{children:"Point lights: Represent localized light sources"}),"\n",(0,r.jsx)(e.li,{children:"Spot lights: Model flashlight or headlight effects"}),"\n",(0,r.jsx)(e.li,{children:"Area lights: For soft, realistic lighting (requires URP/LWRP)"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"lighting-considerations-for-perception",children:"Lighting Considerations for Perception"}),"\n",(0,r.jsx)(e.p,{children:"For perception simulation:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Use realistic light intensities (lux values)"}),"\n",(0,r.jsx)(e.li,{children:"Consider dynamic lighting conditions"}),"\n",(0,r.jsx)(e.li,{children:"Account for shadows affecting sensor data"}),"\n",(0,r.jsx)(e.li,{children:"Include ambient lighting for realistic rendering"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"human-robot-interaction-elements",children:"Human-Robot Interaction Elements"}),"\n",(0,r.jsx)(e.p,{children:"Creating interfaces and elements that facilitate natural interaction between humans and robots in the simulation environment."}),"\n",(0,r.jsx)(e.h3,{id:"user-interface-design",children:"User Interface Design"}),"\n",(0,r.jsx)(e.h4,{id:"canvas-setup-for-hri",children:"Canvas Setup for HRI"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing UnityEngine.UI;\n\npublic class HumanRobotInterface : MonoBehaviour\n{\n    public Canvas canvas;\n    public Button[] robotControls;\n    public Text statusText;\n\n    void Start()\n    {\n        // Initialize UI elements\n        foreach(Button btn in robotControls)\n        {\n            btn.onClick.AddListener(() => OnRobotControl(btn.name));\n        }\n    }\n\n    void OnRobotControl(string command)\n    {\n        // Send command to robot\n        Debug.Log($"Sending command: {command}");\n    }\n}\n'})}),"\n",(0,r.jsx)(e.h3,{id:"gesture-recognition",children:"Gesture Recognition"}),"\n",(0,r.jsx)(e.p,{children:"For simulating gesture-based interaction:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Use Unity's Input System for gesture capture"}),"\n",(0,r.jsx)(e.li,{children:"Implement gesture recognition algorithms"}),"\n",(0,r.jsx)(e.li,{children:"Provide visual feedback for recognized gestures"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"voice-command-simulation",children:"Voice Command Simulation"}),"\n",(0,r.jsx)(e.p,{children:"For voice interaction simulation:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Use Unity's audio system"}),"\n",(0,r.jsx)(e.li,{children:"Implement keyword recognition"}),"\n",(0,r.jsx)(e.li,{children:"Provide visual feedback for command acknowledgment"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"practical-examples",children:"Practical Examples"}),"\n",(0,r.jsx)(e.h3,{id:"example-1-creating-a-basic-humanoid-robot-scene",children:"Example 1: Creating a Basic Humanoid Robot Scene"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Import robot model (URDF or FBX format)"}),"\n",(0,r.jsx)(e.li,{children:"Set up basic lighting"}),"\n",(0,r.jsx)(e.li,{children:"Create a simple environment"}),"\n",(0,r.jsx)(e.li,{children:"Add basic controls"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"example-2-unity-scene-with-humanoid-robot-navigation",children:"Example 2: Unity Scene with Humanoid Robot Navigation"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:"using UnityEngine;\nusing UnityEngine.AI;\n\npublic class HumanoidNavigator : MonoBehaviour\n{\n    public Transform target;\n    public NavMeshAgent agent;\n\n    void Start()\n    {\n        agent = GetComponent<NavMeshAgent>();\n    }\n\n    void Update()\n    {\n        if(target != null)\n        {\n            agent.SetDestination(target.position);\n        }\n    }\n}\n"})}),"\n",(0,r.jsx)(e.h3,{id:"example-3-sensor-visualization-in-unity",children:"Example 3: Sensor Visualization in Unity"}),"\n",(0,r.jsx)(e.p,{children:"Creating a script to visualize sensor data:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\n\npublic class SensorVisualizer : MonoBehaviour\n{\n    public float detectionRadius = 5.0f;\n    public LayerMask detectionLayers;\n\n    void OnDrawGizmosSelected()\n    {\n        // Draw sensor detection range in editor\n        Gizmos.color = Color.red;\n        Gizmos.DrawWireSphere(transform.position, detectionRadius);\n    }\n\n    void FixedUpdate()\n    {\n        // Detect objects in sensor range\n        Collider[] hits = Physics.OverlapSphere(transform.position, detectionRadius, detectionLayers);\n\n        foreach(Collider hit in hits)\n        {\n            if(hit.transform != transform) // Don\'t detect self\n            {\n                Debug.Log($"Sensor detected: {hit.name}");\n            }\n        }\n    }\n}\n'})}),"\n",(0,r.jsx)(e.h2,{id:"integration-with-robotics-frameworks",children:"Integration with Robotics Frameworks"}),"\n",(0,r.jsx)(e.h3,{id:"unity-rosbridge-integration",children:"Unity-Rosbridge Integration"}),"\n",(0,r.jsx)(e.p,{children:"For ROS integration:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Use unity-rosbridge for communication"}),"\n",(0,r.jsx)(e.li,{children:"Set up publishers/subscribers for robot data"}),"\n",(0,r.jsx)(e.li,{children:"Implement service clients for robot commands"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"perception-pipeline",children:"Perception Pipeline"}),"\n",(0,r.jsx)(e.p,{children:"Setting up perception simulation:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Configure cameras for RGB and depth data"}),"\n",(0,r.jsx)(e.li,{children:"Set up LiDAR simulation using raycasting"}),"\n",(0,r.jsx)(e.li,{children:"Process sensor data for perception algorithms"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"exercises-for-students",children:"Exercises for Students"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Create a Unity scene with a simple humanoid robot navigating a maze"}),"\n",(0,r.jsx)(e.li,{children:"Implement a basic human-robot interface with buttons and status indicators"}),"\n",(0,r.jsx)(e.li,{children:"Set up a perception system with cameras and process the image data"}),"\n",(0,r.jsx)(e.li,{children:"Create an interactive environment where the robot responds to human gestures"}),"\n",(0,r.jsx)(e.li,{children:"Implement a basic LiDAR simulation system and visualize the point cloud data"}),"\n"]})]})}function h(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},8453(n,e,i){i.d(e,{R:()=>s,x:()=>a});var t=i(6540);const r={},o=t.createContext(r);function s(n){const e=t.useContext(o);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:s(n.components),t.createElement(o.Provider,{value:e},n.children)}}}]);